{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NehaParveen03/my_first_report/blob/main/Theory_LargeLanguageModels_Dev.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "469e2d86"
      },
      "source": [
        "# <font color = 'yellow'>**Introduction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc74596f"
      },
      "source": [
        "Let’s imagine a conversation with a friend, where the friend starts a sentence with: `I’m going to make a cup of ________.` Humans would likely predict that the next word could be coffee or tea based on their knowledge of common beverage choices.\n",
        "\n",
        "Similarly, a language model is trained to understand and predict the next word in a sequence based on the context of the preceding words. It learns from vast amounts of text data and can make informed predictions about what word will likely come next in a given context."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0782cea2"
      },
      "source": [
        "# <font color = 'yellow'>**Language models**\n",
        "\n",
        "A language model (LM) can be defined as a probabilistic model that assigns probabilities to sequences of words or tokens in a given language. The goal is to capture the structure and patterns of the language to predict the likelihood of a particular sequence of words. It's like training  LLM's understand universal standards of meanings and words\n",
        "\n",
        "Let’s assume we have a vocabulary 𝑉 that contains a sequence of words or tokens denoted as 𝑤1,𝑤2,…,𝑤𝑛 where 𝑛 is the length of the sequence. The LM assigns probabilities (𝑝) to every possible sequence or order of words belonging to a vocabulary (𝑉).\n",
        "\n",
        "The probability of the entire sequence can be expressed as follows:\n",
        "                    \n",
        "                    p(𝑤1,𝑤2,…,𝑤𝑛)\n",
        "                    \n",
        "Assume we have 𝑉 = {chase, the, cat, the, mouse}, and following probabilities (𝑝) assigned:\n",
        "\n",
        "- `p{chase, the, cat, the, mouse}` = 0.0001\n",
        "- `p{the, chase, cat, the, mouse}` = 0.003\n",
        "- `p{chase, the, mouse, the, cat}` = 0.0021\n",
        "- `p{the, cat, chase, the, mouse}` = 0.02\n",
        "- `p{the, mouse, chase, the, cat}` = 0.01\n",
        "\n",
        "Language models must have external knowledge for them to be able to assign meaningful probabilities; therefore, they are trained. During this training process, the model learns to assign higher probabilities to words more likely to follow a given context. After training, the language model can generate text by sampling words based on these learned probabilities.\n",
        "\n",
        "We can also predict a word given a sequence. A language model estimates this probability by considering the conditional probabilities of each word given the previous words in the sequence.\n",
        "\n",
        "    p(𝑤1,𝑤2,…,𝑤𝑛) = p(w1).p(w2|w1).p(w3|w1, w2).p(w4|w1, w2, w3).p(wn|w1, w2, w3,...wn-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **I am standing on the `bank` of the river**\n",
        "\n",
        "* **The `bank` of india is one of the best in the country**"
      ],
      "metadata": {
        "id": "j6PB8qVw5leH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ef3b6eb"
      },
      "source": [
        "**For example**:\n",
        "\n",
        "𝑝(the, cat, chase, the, mouse) =\n",
        "𝑝(the).𝑝(cat|the).𝑝(chase|the, cat).𝑝(the|the, cat, chase).𝑝(mouse|the, cat, chase, the)\n",
        "\n",
        "Practically modeling these conditional probabilities accurately is a complex task. Modern language models, such as Transformer-based models like GPT-3, utilize deep learning techniques to capture intricate patterns and dependencies in the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9926b22a"
      },
      "source": [
        "## **N-gram language model**\n",
        "\n",
        "**N-gram models** are a type of probabilistic language model used in natural language processing and computational linguistics. These models are based on the idea that the probability of a word depends on the previous 𝑛−1 words in the sequence. The term “n-gram” refers to a consecutive sequence of 𝑛 items.\n",
        "\n",
        "For example, consider the following sentence: I love language models.\n",
        "\n",
        "- **Unigram (1-gram)**: “I,” “love,” “language,” “models”\n",
        "\n",
        "- **Bigram (2-gram)**: “I love,” “love language,” “language models”\n",
        "\n",
        "- **Trigram (3-gram)**: “I love language,” “love language models”\n",
        "\n",
        "- **4-gram**: “I love language models”\n",
        "\n",
        "N-gram models are simple and computationally efficient, making them suitable for various natural language processing tasks. However, their limitations include the inability to capture long-range dependencies in language and the sparsity problem when dealing with higher-order n-grams."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "918558d4"
      },
      "source": [
        "# <font color = 'yellow'>**Large Language Models**\n",
        "\n",
        "**Large language models (LLMs)** refer to advanced natural language processing models trained on massive amounts of textual data. These models are designed to understand and generate human-like text based on the input they receive.\n",
        "\n",
        "**LLMs** :\n",
        "- Have tens to hundreds of billions of parameters.\n",
        "- are trained on vast and diverse datasets from the internet.\n",
        "- are highly versatile, excelling across various NLP tasks.\n",
        "- Demand significant computational power and specialized hardware.\n",
        "- are used for complex language understanding, translation, summarization, creative writing.\n",
        "\n",
        "Most notable LLMs in recent years have been built on the Transformer architecture. Previously, most language models relied on convolutional or recurrent neural networks, but the advent of Transformer models has revolutionized language model performance. The core strength of the Transformer models is their ability to process text in parallel, increasing efficiency for language tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fbe9f45"
      },
      "source": [
        "## <font color = 'cyan'>**Types of LLMs**\n",
        "\n",
        "Language representation models are characterized by their emphasis on bidirectional context understanding. These models capture contextual embeddings for words by considering both the left and right context in a sentence. The generated embeddings allow the model to create representations that reflect the meaning of a word based on its surrounding context.\n",
        "\n",
        "- **Zero-shot learning models** possess a distinctive capability to perform tasks without specific training. These models, often exemplified by the GPT series, leverage their generative nature to generate text relevant to a given prompt, even if the task was not explicitly part of their training. This generality and broad applicability enable zero-shot learning models to be applied to various tasks without requiring task-specific fine-tuning. Their proficiency in understanding context, derived from pretraining on diverse datasets, allows them to generate coherent responses across domains.\n",
        "\n",
        "![zero-shot-2.png](attachment:zero-shot-2.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18637381"
      },
      "source": [
        "- **Multi-shot learning models** excel in adapting to tasks with few examples. The essence of multi-shot learning lies in providing the model with limited examples for a specific task, allowing it to perform well with minimal training. With their context-awareness and understanding of relationships between words, models showcase adaptability to tasks characterized by a scarcity of task-specific data. This adaptability is rooted in their pretraining on extensive datasets, which enables them to understand context effectively.\n",
        "\n",
        "![multi-shot-2.png](attachment:multi-shot-2.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5a887ea"
      },
      "source": [
        "- **Fine-tuned or domain-specific models** represent a category where models undergo additional training tailored to specific tasks or domains after initial pretraining on a general dataset. Task-specific optimization involves training the model on datasets specific to the intended application, enhancing its performance in targeted scenarios. Some models, like those in the biomedical field, are fine-tuned or specialized for specific domains, tailoring their knowledge to the nuances of that particular context. Fine-tuning enables these models to adapt to the intricacies of specific tasks or domains, resulting in improved performance and task-specific expertise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1cad9bf"
      },
      "source": [
        "## <font color = 'yellow'>**LLM Challenges**\n",
        "\n",
        "**Data Challenges**:\n",
        "\n",
        "- **`Data Bias`**: The presence of prejudices and imbalances in the training data leading to biased model outputs.\n",
        "- **`Limited World Knowledge and Hallucination`**: LLMs may lack comprehensive understanding of real-world events and information and tend to hallucinate information. Note that training them on new data is a long and expensive process.\n",
        "- **`Dependency on Training Data Quality`**: LLM performance is heavily influenced by the quality and representativeness of the training data.\n",
        "\n",
        "**Technical Challenges**\n",
        "\n",
        "- **`Computational Resources`**: Significant computing power required for training and deploying large language models.\n",
        "\n",
        "- **`Evaluation`**: Evaluation presents a notable challenge as assessing models across diverse tasks and domains is inadequately designed, particularly due to the challenges posed by freely generated content.\n",
        "\n",
        "- **`Fine-tuning Challenges`**: Difficulties in adapting pre-trained models to specific tasks or domains.\n",
        "\n",
        "- **`Contextual Understanding`**: LLMs may face challenges in maintaining coherent context over longer passages or conversations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b373ee4"
      },
      "source": [
        "## <font color = 'pink'>**LLM Use-Cases**\n",
        "\n",
        "![llm%20use%20cases.png](attachment:llm%20use%20cases.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "219bdf3a"
      },
      "source": [
        "### <font color = 'green'>Using LLMs effectively\n",
        "\n",
        "While general AI models such as ChatGPT demonstrate impressive text generation abilities across various subjects, they may lack the depth and nuanced understanding required for specific domains. Additionally, these models are more prone to generating inaccurate or contextually inappropriate content, referred to as hallucinations.\n",
        "\n",
        "For instance, in healthcare, specific terms like `\"electronic health record interoperability\"` or `\"patient-centered medical home\"` hold significant importance, but a generic language model may struggle to fully comprehend their relevance due to a lack of specific training on healthcare data.\n",
        "\n",
        "This is where task-specific and domain-specific LLMs play a crucial role. These models need to possess specialized knowledge of industry-specific terminology and practices to ensure accurate interpretation of domain-specific concepts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9df12fad"
      },
      "source": [
        "**Here are some benefits of using domain-specific LLMs**:\n",
        "\n",
        "- **Depth and Precision**: Domain-specific LLMs are tailored to understand and interpret industry-specific terminology, ensuring precision in comprehension.\n",
        "\n",
        "- **Overcoming Limitations**: In domains like finance or medicine, where specific terminology is crucial, domain-specific LLMs excel in providing accurate and contextually relevant information.\n",
        "\n",
        "- **Enhanced User Experiences**: Domain-specific LLMs contribute to enhanced user experiences by offering tailored and personalized responses. In applications such as customer service chatbots or dynamic AI agents, these models leverage specialized knowledge to provide more accurate and insightful information.\n",
        "\n",
        "- **Improved Efficiency and Productivity**: Businesses can benefit from the improved efficiency of domain-specific LLMs. By automating tasks, generating content aligned with industry-specific terminology, and streamlining operations, these models free up human resources for higher-level tasks, ultimately boosting productivity.\n",
        "\n",
        "- **Addressing Privacy Concerns**: In industries dealing with sensitive data, such as healthcare, using general LLMs may pose privacy challenges. Domain-specific LLMs can provide a closed framework, ensuring the protection of confidential data and adherence to privacy agreements."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdbc5d56"
      },
      "source": [
        "Previously we saw that we had multiple ways to use LLMs in specific use cases, namely\n",
        "\n",
        "- Zero-shot learning\n",
        "- Few-shot/Multi-shot learning\n",
        "- Domain Specific models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70bd8f41"
      },
      "source": [
        "### <font color = 'yellow'>**Types of Domain Specific Methods**</font>\n",
        "\n",
        "**1. Domain-Specific Pre-Training**:\n",
        "\n",
        "  **Training Duration**: Days to weeks to months\n",
        "\n",
        "Domain-specific pre-training involves training large language models on extensive datasets (for instance, `models like PaLM 540B, GPT-3, and LLaMA 2 have been pre-trained on datasets with sizes ranging from 499 billion to 2 trillion tokens`) that specifically represent the language and characteristics of a particular domain or field. This process aims to enhance the model's understanding and performance within a defined subject area.\n",
        "\n",
        "Examples of domain-specific pre-training include models like `ESMFold, ProGen2 for protein sequences, Galactica for science, BloombergGPT for finance, and StarCoder for code`. These models outperform generalist models within their domains.\n",
        "\n",
        "**Let’s understand domain specific pretraining through the example of `BloombergGPT`, a large language model for finance**.\n",
        "\n",
        "BloombergGPT is a `50 billion parameter` language model designed to excel in various tasks within the financial industry. While general models are versatile and perform well across diverse tasks, they may not outperform domain-specific models in specialized areas. At Bloomberg, where a significant majority of applications are within the financial domain, there is a need for a model that excels in financial tasks while maintaining competitive performance on general benchmarks. BloombergGPT can perform the following tasks:\n",
        "\n",
        "- `Financial Sentiment Analysis`: Analyzing and determining sentiment in financial texts, such as news articles, social media posts, or financial reports.\n",
        "\n",
        "- `Named Entity Recognition`: Identifying and classifying entities (such as companies, individuals, and financial instruments) mentioned in financial documents.\n",
        "\n",
        "- `News Classification`: Categorizing financial news articles into different topics or classes.\n",
        "\n",
        "- `Question Answering in Finance`: Answering questions related to financial topics.\n",
        "\n",
        "- `Conversational Systems for Finance`: Engaging in natural language conversations related to finance.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef449332"
      },
      "source": [
        "**2. Domain-Specific Fine-Tuning**:\n",
        "\n",
        "Training Duration: Minutes to hours\n",
        "\n",
        "`Domain-specific fine-tuning` is the process of refining a `pre-existing language model` for a particular task or within a specific domain to enhance its performance and tailor it to the unique context of that domain. This method involves taking an LLM that has undergone pre-training on a diverse dataset encompassing various language use cases and subsequently fine-tuning it on a narrower dataset specifically related to a particular domain or task.\n",
        "\n",
        "💡Note that the previous method, i.e., `domain-specific pre-training` involves training a language model exclusively on data from a specific domain, creating a specialized model for that domain. On the other hand, `domain-specific fine-tuning` takes a pre-trained general model and further trains it on `domain-specific data`, adapting it for tasks within that domain without starting from scratch. Pre-training is domain-exclusive from the beginning, while fine-tuning adapts a more versatile model to a specific domain.\n",
        "\n",
        "**Domain-specific fine-tuning offers several advantages**:\n",
        "\n",
        "- It enables the model to specialize in a particular domain, enhancing its effectiveness for tasks within that domain.\n",
        "- It saves time and computational resources compared to training a model from scratch, leveraging the knowledge gained during pre-training.\n",
        "- The model can adapt to the specific requirements and nuances of the target domain, leading to improved performance on domain-specific tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69a5dff3"
      },
      "source": [
        "**3. Retrieval Augmented Generation (RAG)**\n",
        "\n",
        "Retrieval Augmented Generation (RAG) is an AI framework that enhances the quality of responses generated by LLMs by incorporating up-to-date and contextually relevant information from external sources during the generation process.\n",
        "\n",
        "RAG involves two phases: `retrieval`, where relevant information is searched and retrieved, and `content generation`, where the LLM synthesizes an answer based on the retrieved information and its internal training data. This approach improves accuracy, allows source verification, and reduces the need for continuous model retraining."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85a80520"
      },
      "source": [
        "#### Choosing Between RAG, Domain-Specific Fine-Tuning, and Domain-Specific Pre-Training\n",
        "\n",
        "#### When to Use Domain-Specific Pre-Training:\n",
        "\n",
        "- `Exclusive Domain Focus`: Pre-training is suitable when you require a model exclusively trained on data from a specific domain, creating a specialized language model for that domain.\n",
        "- `Customizing Model Architecture`: It allows you to customize various aspects of the model architecture, size, tokenizer, etc., based on the specific requirements of the domain.\n",
        "- `Extensive Training Data Available`: Effective pre-training often requires a large amount of domain-specific training data to ensure the model captures the intricacies of the chosen domain.\n",
        "\n",
        "#### When to Use Domain-Specific Fine-Tuning:\n",
        "\n",
        "- `Specialization Needed`: Fine-tuning is suitable when you already have a pre-trained LLM, and you want to adapt it for specific tasks or within a particular domain.\n",
        "- `Task Optimization`: It allows you to adjust the model's parameters related to the task, such as architecture, size, or tokenizer, for optimal performance in the chosen domain.\n",
        "- `Time and Resource Efficiency`: Fine-tuning saves time and computational resources compared to training a model from scratch since it leverages the knowledge gained during the pre-training phase.\n",
        "\n",
        "#### When to Use RAG:\n",
        "\n",
        "- `Information Freshness Matters`: RAG provides up-to-date, context-specific data from external sources.\n",
        "- `Reducing Hallucination is Crucial`: Ground LLMs with verifiable facts and citations from an external knowledge base.\n",
        "- `Cost-Efficiency is a Priority`: Avoid extensive model training or fine-tuning; implement without the need for training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31764c91"
      },
      "source": [
        "### Fine-Tuning LLMs\n",
        "\n",
        "Fine-tuning refers to the process of adjusting the parameters of a pretrained model on a specific dataset to enhance its performance on a specific task. In large language models, fine-tuning is generally used to transform a foundation model into a specialized one for a particular use case.\n",
        "\n",
        "Fine-tuning large language models brings several key benefits. It sharpens the model’s skills for specific jobs, like answering medical questions or writing legal documents. Learning how to fine-tune models can help individuals adapt powerful large language models for their specific use cases.\n",
        "\n",
        "#### Need for fine tuning\n",
        "\n",
        "Fine-tuning is a crucial step in ensuring that the general-purpose foundation models are aligned with the specific needs of users. The first versions of GPT-3 were foundation models that had been trained on a vast and diverse dataset for text completion. These models could accurately predict the next word in a sentence. However, as they were not trained to specifically follow instructions from users, these models had the potential of generating inaccurate or misleading outputs unrelated to the users’ instructions.\n",
        "\n",
        "The researchers at OpenAI fine-tuned GPT-3 on a prompt-based dataset to make the models safer and more helpful for their users. This fine-tuning resulted in the InstructGPT models that excel at following user prompts and generating outputs more aligned with the given instructions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8ea84f4"
      },
      "outputs": [],
      "source": []
    }
  ]
}